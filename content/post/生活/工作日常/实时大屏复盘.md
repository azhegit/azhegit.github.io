---
categories:
- 生活
date: '2022-12-13 22:57:55+08:00'
tags:
- 工作日常
thumbnailImage: //www.azheimage.top/markdown-img-paste-20180831191423561.png
title: 实时大屏复盘
---

# 实时大屏复盘

<!--more-->

![](https://www.azheimage.top/markdown-img-paste-20211215195323445.png)

## 一、项目回顾

### 1.1 项目目标

- 1.0 版本：为了 Q4 实时计算能有明确的产出，以及为了明年 618 面向商家的大屏能够从内部孵化，带商家金额 TopN
- 1.1 版本：数据安全考虑，第一版方案中的商家排名模块暂不展示，目标客户内部领导
- 1.2 版本：双十二提供给个别商家内测。

### 1.2 项目过程

![](https://www.azheimage.top/markdown-img-paste-20211215112347995.png)

### 1.3 结果产出

目前 v1.1，v1.2 两个版本内测试运行

## 二、 上线异常点回顾

### 2.1 过程中异常点

#### 1. 12-12 00:01 DataV 版本切换故障

##### 直接影响

双链路，从数据正常版本切换至数据异常版本

##### 过程分析

1. 预生产运行 SQL 版本相对稳定，可调整空间大，所以生产版本优先选择 SQL 版本
2. 在 12-11 21:30，草履担心状态太大，任务运行异常，提出任务重启操作，象牙确认低风险操作
3. DataV 在切换至星毛 DataStream 版本
4. 12-11 21:37 SQL 版本重启
   ![](https://www.azheimage.top/markdown-img-paste-20211215160403755.png)
5. 12-11 21:49 重启成功，并且数据正常
   ![](https://www.azheimage.top/markdown-img-paste-2021121516104841.png)
6. 12-12 00:01 部分商家有数据，部分商家没数据
7. **12-12 00:01 依然部分没有结果，默认 SQL 版本是正常(任务运行状态 running，此刻忽略了去排查 SQL 版本数据结果)，切换至 SQL 版本**
8. **切完之后，发现 SQL 版本大概刷新了 2 次数据全都没有，立刻切回 DataStream 版本，恢复正常**
9. 12-12 00:02 所有商家订单数据均有结果

##### 处理方式

双链路切回正常链路（人工干预）

##### 总结原因

1. 生产中正常链路不随意切换，无论主备
2. 生产链路切换一定要确保万无一失

#### 2. 12-12 00:02 SQL 版本切 0 点运行异常

##### 直接影响

运行异常导致任务重启，重启次数设置为 4 次，重试 4 次之后从任务启动点，点位重跑

##### 过程分析

1. 在链路切换，发现 SQL 版没数据，意识到任务运行异常
2. 00:02 钉钉告警重启次数超过 1 次，此刻 DataV 切回 DataStream 版本，显示正常
   ![](https://www.azheimage.top/markdown-img-paste-20211215162845368.png)
3. 00:02 草履开始排查重启原因
4. 00:07 溪竹找阿里云同事协助排查
   ![](https://www.azheimage.top/markdown-img-paste-20211215163617371.png)
5. 00:14 直接原因是分区未创建导致任务失败
   ![](https://www.azheimage.top/markdown-img-paste-20211215163821109.png)

##### 处理方式

1. 平台自动重启 4 次失败引发另一个问题点
2. DataStream 版本稳定运行（人工干预）

##### 总结原因

01:10 确认平台首现 bug
![](https://www.azheimage.top/markdown-img-paste-20211215181045173.png)

#### 3. 00:02 任务自动重启，次数超过依然不成功会从任务启动点位重新消费

##### 直接影响

导致消息点位重置

1. 追数据会导致 kafka 消费流量被打满
2. 如果任务启动时间长，会导致重算多天的数据

##### 过程分析

1. 00:01 因为 holo 分区未自动创建(配置了自动创建、隐藏 bug)导致任务失败重启
2. 作业配置重启次数 4 次
3. 重启 4 次之后，重置点位到任务启动，因任务在 12-11 21:30 启动任务，指定消费点位为 11 号 0 点
   ![](https://www.azheimage.top/markdown-img-paste-20211215190633507.png)

##### 处理方式

1. 00:10 任务停止，重置点位为 12-11 23:00 启动，计算 12-12 号当天结果
   ![](https://www.azheimage.top/markdown-img-paste-2021121519091999.png)

##### 总结原因

平台重启策略相关，重置为任务启动点 kafka 点位，并且无法人工干预，设计是否合理？

#### 4. 12-12 9 点 消费积压 20min

##### 直接影响

消费积压带来的影响是后续计算任务数据会被延迟产出结果，分钟级延迟 9 点~11 点 19 分，最大延迟 22min。

##### 过程分析

1. 12-12 09:32 星毛发现任务延迟，上午流量高峰期，不止订单，还有物流同步任务流量比较大
   ![](https://www.azheimage.top/markdown-img-paste-20211215191519998.png)
2. 12-12 09:32~11:19 溪竹、象牙、东云、星毛一直在监控 kafka 流量情况，期间任务延迟最大量为 22min
   ![](https://www.azheimage.top/markdown-img-paste-20211215191857738.png)
3. 11:19 任务恢复正常
   ![](https://www.azheimage.top/markdown-img-paste-2021121519221178.png)

##### 处理方式

1. 计算任务人工未干预
2. kafka 配置流量峰值监控
3. flink 平台配置时延监控

##### 总结原因

- 直接原因受 kafka 流控影响，导致去重数据回写 kafka 的时候，去重任务产生背压，分钟级延迟 9 点~11 点 19 分，最大延迟 22min，任务延迟是任务级别的，并没有细化到商家，所以有的商家是延迟很低，最大延迟可能达到 22min
- 期间没有做任何变更，一直在监控上下游以及任务运行情况，没有做干预，10 点 40 左右上游及其他业务流量下降，去重任务开始追赶，目前任务链路正常
- kafka 写入流控 80M，消费流控 240M，在流量高峰期 kafka 流量被打满，链路被延迟

#### 5. 12-12 23:21 消费延迟 50s，持续时间 6min

![](https://www.azheimage.top/markdown-img-paste-20211215192326378.png)

#### 6. 跨天之后，折线图会显示昨天，0:02 分，当天订单结果产出之后消除

![](https://www.azheimage.top/markdown-img-paste-20211215192512767.png)

#### 7. 两三家，同比数据稀疏，导致折线看着有些许奇怪

![](https://www.azheimage.top/markdown-img-paste-20211215192540171.png)

#### 8. 物流公司没数据，饼图为空，有发货单，确定物流平台之后消除

![](https://www.azheimage.top/markdown-img-paste-20211215192608777.png)

### 2.2 脑暴（主题：过程中问题点）

## 三、 调整方案

### 1. kafka 数据发送端开启 gzip 压缩减少流量

- 去重任务(压缩之后是压缩之前 30~40%) **已调整**
- SQL 计算任务已调整(压缩之后是压缩之前~50%) **已调整**

### 2. 跨天之后，折线图在数据没进来之前(持续 0-3 分钟)会显示昨天

今日折线图统计结果未出来之前，SQL 查到的其实是同比的折线数据，datav 显示为今日结果(误以为是昨天的今日统计结果)

#### 处理方式:

凤林对 datav 调整，拿到 SQL 查询的结果，今日无结果，对同比数据正确展示

### 3. 同比数据稀疏，导致折线看着有些许奇怪

#### 处理方式:

datav 处理,物流平台分布，电商平台分布结果未出来是默认文案或者默认图案展示

### 4. 大屏数据延时监控

通过 grafana+prometheus 对商家大屏延时监控+告警（已配置、测试中）

## 四、 持续提升

### 1. Flink SQL 任务命名规范

### 2. 实时任务结果表，建表命名规范

### 3. Flink 任务资源控制

原则：保证最低资源消耗情况下，正常流量峰值 Buffer50%
目标：缩减 50~70%

### 4. Flink 任务上线流程

### 5. 实时任务 kafka 集群单独管控？

### 6. kafka 自动扩缩容方案？

### 7. 同步链路告警
